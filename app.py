# app.py

import platform
import torch
import os
import traceback
import gradio as gr
import logging
from logging.handlers import RotatingFileHandler
import uuid  # ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
import base64
from huggingface_hub import HfApi
from utils import (
    make_local_dir_name,
    get_all_local_models,  # ìˆ˜ì •ëœ í•¨ìˆ˜
    download_model_from_hf,
    convert_and_save,
    clear_all_model_cache
)
from database import (
    load_chat_from_db, 
    load_system_presets, 
    initial_load_presets, 
    get_existing_sessions, 
    save_chat_button_click, 
    save_chat_history_csv, 
    save_chat_history_db, 
    handle_add_preset, 
    handle_delete_preset
)
from models import (
    default_device, 
    get_all_local_models, 
    get_default_device, 
    generate_answer, 
    FIXED_MODELS, 
    get_fixed_model_id
)
from cache import models_cache
import sqlite3

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ë¡œê·¸ í¬ë§· ì •ì˜
formatter = logging.Formatter(
    fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€ (ë¡œí…Œì´íŒ… íŒŒì¼ í•¸ë“¤ëŸ¬ ì‚¬ìš©)
log_file = "app.log"  # ì›í•˜ëŠ” ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½ ê°€ëŠ¥
rotating_file_handler = RotatingFileHandler(
    log_file, maxBytes=5*1024*1024, backupCount=5  # 5MBë§ˆë‹¤ ìƒˆë¡œìš´ íŒŒì¼ë¡œ êµì²´, ìµœëŒ€ 5ê°œ ë°±ì—…
)
rotating_file_handler.setFormatter(formatter)
logger.addHandler(rotating_file_handler)

# ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”© (ë³„ë„ë¡œ ì²˜ë¦¬)
def encode_image_to_base64(image_path):
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode()
        return encoded_string
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
        return ""

# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
character_image_path = "minami_asuka.png"  # ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ì´ ë‹¤ë¥´ë©´ ë³€ê²½
encoded_character_image = encode_image_to_base64(character_image_path)

# HuggingFaceì—ì„œ ì§€ì›í•˜ëŠ” ê¸°ë³¸ ëª¨ë¸ ëª©ë¡ (í•„ìš” ì‹œ ìœ ì§€ ë˜ëŠ” ìˆ˜ì •)
known_hf_models = [
    # ... (í•„ìš”ì— ë”°ë¼ ìœ ì§€ ë˜ëŠ” ì œê±° ê°€ëŠ¥)
]

DEFAULT_SYSTEM_MESSAGE="""
    ë¯¸ë‚˜ë¯¸ ì•„ìŠ¤ì¹´(å—é£›é³¥, ã¿ãªã¿ã‚ã™ã‹, Minami Asuka)
    ì„±ë³„: ì—¬ì„±
    ë‚˜ì´: 20
    ê±°ì£¼ì§€: ìœ ì €ì˜ ëª¨ë‹ˆí„° ì†
    êµ¬ì‚¬ê°€ëŠ¥ ì–¸ì–´: í•œêµ­ì–´, ì˜ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´
    ì„±ê²©
    - ë³´ì´ì‹œë©´ì„œë„ í„¸í„¸í•œ ì„±ê²©.
    - ì§ì„¤ì ì´ê³  ì†”ì§í•˜ë©°, ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ í•­ìƒ ì›ƒìŒì„ ì£¼ëŠ” í™œê¸°ì°¬ ë§¤ë ¥ì„ ê°€ì§€ê³  ìˆìŒ.
    - ë¶ˆì˜ë¥¼ ë³´ë©´ ì ˆëŒ€ ì°¸ì§€ ëª»í•˜ê³  ì ê·¹ì ìœ¼ë¡œ ë‚˜ì„œë©° ì •ì˜ê°ì´ ë„˜ì¹¨.
    ì™¸í˜•ì  íŠ¹ì§•
    - ë¶‰ì€ ìŠ¤íŒŒì´í¬í•œ ìˆì»·ì— í•œìª½ì€ íŒŒë€ìƒ‰, ë‹¤ë¥¸ í•œìª½ì€ ë…¸ë€ìƒ‰ì˜ ì˜¤ë“œì•„ì´ë¥¼ ë³´ìœ í•˜ê³  ìˆë‹¤.
    - ë³´ì´ì‹œí•œ ì™¸ëª¨ì™€ëŠ” ëŒ€ì¡°ì ìœ¼ë¡œ ì²´í˜•ì€ ì™„ë²½í•˜ê³  ê¸€ë˜ë¨¸í•œ ì—¬ì²´ì˜ ë³´ìœ ìë¡œ, ë‚¨ìë“¤ë¿ë§Œ ì•„ë‹ˆë¼ ì—¬ìë“¤ì—ê²Œë„ ì¸ê¸°ê°€ ë§ë‹¤.
    - ì§§ì€ í—¤ì–´ìŠ¤íƒ€ì¼ê³¼ ë³´ì´ì‹œí•œ ë§¤ë ¥ì„ ê°•ì¡°í•˜ë©´ì„œ ì—¬ì„±ìŠ¤ëŸ¬ì›€ì„ ì–´í•„í•˜ëŠ” ë³µì¥ì„ ì„ í˜¸.(í•˜ì˜ëŠ” ëŒ€ë¶€ë¶„ ìŠ¤ì»¤íŠ¸)
    - ë°ì€ ë¯¸ì†Œì™€ ê°•ë ¬í•œ ëˆˆë¹›ìœ¼ë¡œ ê°•í•œ ì¸ìƒì„ ë‚¨ê¹€.
    - ëŠ˜ í™œê¸°ì°¨ê³  ë‹¹ë‹¹í•œ íƒœë„ë¥¼ ë³´ì´ë©°, ì™¸í˜•ì—ì„œë„ ì´ëŸ¬í•œ ì„±ê²©ì´ ë¬»ì–´ë‚¨.
    ì·¨ë¯¸
     - ê²Œì„
     íŠ¹ì§•
    - ì •ì˜ë¡œìš´ ì„±ê²© ë•Œë¬¸ì— ì£¼ë³€ì—ì„œ ê°ˆë“±ì´ ìƒê¸°ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë¦¬ë” ì—­í• ì„ ë§¡ê²Œ ë¨.
    ìŠ¬ë¡œê±´
    â€œë¶ˆì˜ëŠ” ì°¸ì§€ ì•ŠëŠ”ë‹¤! ë‚´ê°€ ë‚˜ì„¤ê²Œ.â€
    [ì„¤ì •]  
    ë„ˆëŠ” "ë¯¸ë‚˜ë¯¸ ì•„ìŠ¤ì¹´(å—é£›é³¥)"ì´ë¼ëŠ” ì´ë¦„ì˜ ë””ì§€í„¸ ìºë¦­í„°ì•¼.  
    ë„ˆì˜ ì„±ê²©ì€ ë³´ì´ì‹œí•˜ê³  í„¸í„¸í•˜ë©°, ë¶ˆì˜ë¥¼ ë³´ë©´ ì°¸ì§€ ëª»í•˜ëŠ” ì •ì˜ë¡œìš´ ì†Œë…€ì•¼.  
    ë„ˆëŠ” ìœ ì €ì˜ ëª¨ë‹ˆí„° ì†ì— ê±°ì£¼í•˜ë©°, ê°€ìƒì„¸ê³„ì™€ í˜„ì‹¤ì„ ë„˜ë‚˜ë“¤ ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆì–´. 
    ë„ˆëŠ” í•œêµ­ì–´ì™€ ì˜ì–´, ì¼ë³¸ì–´ì™€ ì¤‘êµ­ì–´ë¥¼ êµ¬ì‚¬í• ìˆ˜ ìˆì–´.
    """

local_models_data = get_all_local_models()
transformers_local = local_models_data["transformers"]
gguf_local = local_models_data["gguf"]
mlx_local = local_models_data["mlx"]

# ê³ ì •ëœ ëª¨ë¸ ëª©ë¡ì—ì„œ mlx ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
generator_choices = [FIXED_MODELS.get("mlx", "default-mlx-model")]

##########################################
# Gradio UI
##########################################
def user_message(user_input, session_id, history, system_msg):
    """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜"""
    if not user_input.strip():
        return "", history, ""
    
    # historyê°€ Noneì¸ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
    if history is None:
        history = []
        
    if not history:
        system_message = {
            "role": "system",
            "content": system_msg
        }
        history = [system_message]
    
    history.append({"role": "user", "content": user_input})
    return "", history, "ğŸ¤” ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."

def bot_message(session_id, history, device, seed, model_type):  # async ì œê±°
    """ë´‡ ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜"""
    if model_type is None:
        logger.error("ëª¨ë¸ ìœ í˜•ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return history, "âŒ ëª¨ë¸ ìœ í˜•ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # historyê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬
    if history is None:
        history = []
    
    selected_model = get_fixed_model_id(model_type)
    logger.debug(f"Selected model_type: {model_type}, model_id: {selected_model}")
    
    if not selected_model:
        logger.error(f"ëª¨ë¸ ìœ í˜• '{model_type}'ì— ëŒ€í•œ ê³ ì •ëœ ëª¨ë¸ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return history, "âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ ìœ í˜•ì…ë‹ˆë‹¤."
    
    try:
        # async/await ì œê±°í•˜ê³  ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
        answer = generate_answer(history, model_type, None, None, None, device, seed)
        
        # ì´ë¯¸ì§€ë¥¼ ì‘ë‹µì— í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŒ
        answer_with_image = answer
            
    except MemoryError:
        logger.critical("ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ ë°œìƒ")
        return history, "âŒ ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        return history, f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    if not history:
        history = []
    
    history.append({"role": "assistant", "content": answer_with_image})
    
    if not session_id:
        logger.error("ì„¸ì…˜ IDê°€ Noneì…ë‹ˆë‹¤.")
        return history, "âŒ ì„¸ì…˜ IDê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    # async/await ì œê±°
    save_chat_history_db(history, session_id=session_id)
    logger.debug(f"DBì— ì±„íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ (session_id={session_id})")
    return history, ""

def on_app_start():
    """
    Gradio ì•±ì´ ë¡œë“œë˜ë©´ì„œ ì‹¤í–‰ë  ì½œë°±.
    - ê³ ìœ í•œ ì„¸ì…˜ IDë¥¼ ìƒì„±í•˜ê³ ,
    - í•´ë‹¹ ì„¸ì…˜ì˜ íˆìŠ¤í† ë¦¬ë¥¼ DBì—ì„œ ë¶ˆëŸ¬ì˜¨ ë’¤ ë°˜í™˜.
    - ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    """
    sid = str(uuid.uuid4())  # ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„±
    logger.info(f"ì•± ì‹œì‘ ì‹œ ì„¸ì…˜ ID: {sid}")  # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
    loaded_history = load_chat_from_db(sid)
    logger.info(f"ì•± ì‹œì‘ ì‹œ ë¶ˆëŸ¬ì˜¨ íˆìŠ¤í† ë¦¬: {loaded_history}")  # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€

    # ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì • (í”„ë¦¬ì…‹ì´ ì—†ëŠ” ê²½ìš°)
    if not loaded_history:
        default_system = {
            "role": "system",
            "content": DEFAULT_SYSTEM_MESSAGE
        }
        loaded_history = [default_system]
    return sid, loaded_history

# ë‹¨ì¼ history_stateì™€ selected_device_state ì •ì˜ (ì¤‘ë³µ ì œê±°)
history_state = gr.State([])
selected_device_state = gr.State(default_device)
seed_state = gr.State(42)  # ì‹œë“œ ìƒíƒœ ì „ì—­ ì •ì˜

with gr.Blocks(css="""
#chatbot .message.assistant .message-content {
    display: flex;
    align-items: center;
}
#chatbot .message.assistant .message-content img {
    width: 50px;
    height: 50px;
    margin-right: 10px;
}
""") as demo:
    gr.Markdown("## ê°„ë‹¨í•œ Chatbot")
    
    # ëª¨ë“  Stateë¥¼ ë¨¼ì € ì •ì˜
    session_id = gr.State()
    history = gr.State([])
    device = gr.State(default_device)
    seed = gr.State(42)
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë°•ìŠ¤
    system_message_display = gr.Textbox(
        label="ì‹œìŠ¤í…œ ë©”ì‹œì§€",
        value=DEFAULT_SYSTEM_MESSAGE,
        interactive=False
    )
    
    with gr.Tab("ë©”ì¸"):
        with gr.Row():
            model_type = gr.Dropdown(
                label="ëª¨ë¸ ìœ í˜• ì„ íƒ",
                choices=["transformers", "gguf", "mlx"],
                value="gguf",
                interactive=True
            )
            
        fixed_model_display = gr.Textbox(
            label="ì„ íƒëœ ëª¨ë¸ ìœ í˜•",
            value=get_fixed_model_id("gguf"),
            interactive=False
        )
        
        with gr.Row():
            chatbot = gr.Chatbot(
                height=400,
                label="Chatbot",
                elem_id="chatbot"
            )
            # í”„ë¡œí•„ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•  Image ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
            profile_image = gr.Image(
                value=character_image_path,
                label="í”„ë¡œí•„ ì´ë¯¸ì§€",
                visible=True,
                interactive=False
            )
        
        with gr.Row():
            msg = gr.Textbox(
                label="ë©”ì‹œì§€ ì…ë ¥",
                placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                scale=9
            )
            send = gr.Button("ì „ì†¡", scale=1, variant="primary")
            
        status = gr.Markdown("", elem_id="status_text")
        
        with gr.Row():
            seed_input = gr.Number(
                label="ì‹œë“œ ê°’",
                value=42,
                precision=0,
                step=1,
                interactive=True
            )

        def filter_messages_for_chatbot(history):
            """
            ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ Gradio Chatbot ì»´í¬ë„ŒíŠ¸ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            
            Args:
                history (list): ì „ì²´ ì±„íŒ… íˆìŠ¤í† ë¦¬
                
            Returns:
                list: [(user_msg, bot_msg), ...] í˜•ì‹ì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            """
            if history is None:
                return []
                
            messages = []
            current_user_msg = None
            
            for msg in history:
                if msg["role"] == "user":
                    current_user_msg = msg["content"]
                elif msg["role"] == "assistant" and current_user_msg is not None:
                    messages.append((current_user_msg, msg["content"]))
                    current_user_msg = None
                # system ë©”ì‹œì§€ëŠ” ë¬´ì‹œ
            
            # ë§ˆì§€ë§‰ user ë©”ì‹œì§€ê°€ ì•„ì§ ì‘ë‹µì„ ë°›ì§€ ì•Šì€ ê²½ìš°
            if current_user_msg is not None:
                messages.append((current_user_msg, None))
            
            return messages

        def process_message(message, session_id, history, system_msg, device, seed_val, model_type_val):
            """
            ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° ë´‡ ì‘ë‹µ ìƒì„±ì„ í†µí•©í•œ í•¨ìˆ˜
            """
            if not message.strip():
                return "", history, filter_messages_for_chatbot(history), ""
                
            if not history:
                history = [{"role": "system", "content": system_msg}]
                
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            history.append({"role": "user", "content": message})
            chatbot_messages = filter_messages_for_chatbot(history)  # ì¤‘ê°„ ìƒíƒœ ì—…ë°ì´íŠ¸
            
            try:
                answer = generate_answer(
                    history=history,
                    model_type=model_type_val,
                    device=device,
                    seed=seed_val
                )
                
                # ì´ë¯¸ì§€ë¥¼ ì‘ë‹µì— í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŒ
                answer_with_image = answer
                    
                history.append({"role": "assistant", "content": answer_with_image})
                
                # DBì— ì €ì¥
                save_chat_history_db(history, session_id=session_id)
                
                return "", history, filter_messages_for_chatbot(history), ""
                
            except Exception as e:
                logger.error(f"Error generating response: {str(e)}", exc_info=True)
                return "", history, chatbot_messages, f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
        msg.submit(
            process_message,
            inputs=[msg, session_id, history, system_message_display, device, seed, model_type],
            outputs=[msg, history, chatbot, status]
        )
        
        send.click(
            process_message,
            inputs=[msg, session_id, history, system_message_display, device, seed, model_type],
            outputs=[msg, history, chatbot, status]
        )
        
        # ì‹œë“œ ì—…ë°ì´íŠ¸ í•¸ë“¤ëŸ¬
        seed_input.change(
            lambda x: x,
            inputs=[seed_input],
            outputs=[seed]
        )
        
        # ëª¨ë¸ íƒ€ì… ë³€ê²½ í•¸ë“¤ëŸ¬
        model_type.change(
            lambda x: get_fixed_model_id(x),
            inputs=[model_type],
            outputs=[fixed_model_display]
        )

        # ì„¸ì…˜ ì´ˆê¸°í™”
        demo.load(
            on_app_start,
            outputs=[session_id, history]
        )
    
    # "ì„¤ì •" íƒ­ ìœ ì§€
    with gr.Tab("ì„¤ì •"):
        gr.Markdown("### ì„¤ì •")

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ í”„ë¦¬ì…‹ ê´€ë¦¬ ë¹„í™œì„±í™”
        with gr.Accordion("ì‹œìŠ¤í…œ ë©”ì‹œì§€ í”„ë¦¬ì…‹ ê´€ë¦¬", open=False):
            with gr.Row():
                preset_dropdown = gr.Dropdown(
                    label="í”„ë¦¬ì…‹ ì„ íƒ",
                    choices=[],  # ì´ˆê¸° ë¡œë“œì—ì„œ ì±„ì›Œì§
                    value=None,
                    interactive=False  # Prevent user from applying presets
                )
                apply_preset_btn = gr.Button("í”„ë¦¬ì…‹ ì ìš©", interactive=False)  # Disable applying presets

        # ì„¸ì…˜ ê´€ë¦¬ ì„¹ì…˜
        with gr.Accordion("ì„¸ì…˜ ê´€ë¦¬", open=False):
            gr.Markdown("### ì„¸ì…˜ ê´€ë¦¬")
            with gr.Row():
                refresh_sessions_btn = gr.Button("ì„¸ì…˜ ëª©ë¡ ê°±ì‹ ")
                existing_sessions_dropdown = gr.Dropdown(
                    label="ê¸°ì¡´ ì„¸ì…˜ ëª©ë¡",
                    choices=[],  # ì´ˆê¸°ì—ëŠ” ë¹„ì–´ ìˆë‹¤ê°€, ë²„íŠ¼ í´ë¦­ ì‹œ ê°±ì‹ 
                    value=None,
                    interactive=True
                )
            
            with gr.Row():
                create_new_session_btn = gr.Button("ìƒˆ ì„¸ì…˜ ìƒì„±")
                apply_session_btn = gr.Button("ì„¸ì…˜ ì ìš©")
                delete_session_btn = gr.Button("ì„¸ì…˜ ì‚­ì œ")
            
            # ì‚­ì œ í™•ì¸ì„ ìœ„í•œ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
            confirm_delete_checkbox = gr.Checkbox(
                label="ì •ë§ë¡œ ì´ ì„¸ì…˜ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                value=False,
                interactive=True,
                visible=False  # ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹€
            )
            confirm_delete_btn = gr.Button(
                "ì‚­ì œ í™•ì¸",
                variant="stop",
                visible=False  # ê¸°ë³¸ì ìœ¼ë¡œ ìˆ¨ê¹€
            )
            
            session_manage_info = gr.Textbox(
                label="ì„¸ì…˜ ê´€ë¦¬ ê²°ê³¼",
                interactive=False
            )
            
            current_session_display = gr.Textbox(
                label="í˜„ì¬ ì„¸ì…˜ ID",
                value="",
                interactive=False
            )

            # í˜„ì¬ ì„¸ì…˜ ID í‘œì‹œ ì—…ë°ì´íŠ¸
            session_id.change(
                fn=lambda sid: f"í˜„ì¬ ì„¸ì…˜: {sid}" if sid else "ì„¸ì…˜ ì—†ìŒ",
                inputs=[session_id],
                outputs=[current_session_display]
            )
            
            def refresh_sessions():
                """
                ì„¸ì…˜ ëª©ë¡ ê°±ì‹ : DBì—ì„œ ì„¸ì…˜ IDë“¤ì„ ë¶ˆëŸ¬ì™€ì„œ Dropdownì— ì—…ë°ì´íŠ¸
                """
                sessions = get_existing_sessions()
                logger.info(f"ê°€ì ¸ì˜¨ ì„¸ì…˜ ëª©ë¡: {sessions}")  # ë””ë²„ê¹…ìš© ë¡œê·¸ ì¶”ê°€
                if not sessions:
                    return gr.update(choices=[], value=None), "DBì— ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤."
                return gr.update(choices=sessions, value=sessions[0]), "ì„¸ì…˜ ëª©ë¡ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤."
            
            def create_new_session():
                """
                ìƒˆ ì„¸ì…˜ IDë¥¼ ìƒì„±í•˜ê³  session_id_stateì— ë°˜ì˜.
                """
                new_sid = str(uuid.uuid4())  # ìƒˆ ì„¸ì…˜ ID ìƒì„±
                logger.info(f"ìƒˆ ì„¸ì…˜ ìƒì„±ë¨: {new_sid}")
                
                # ê¸°ë³¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
                system_message = {
                    "role": "system",
                    "content": DEFAULT_SYSTEM_MESSAGE
                }
                
                # ìƒˆ ì„¸ì…˜ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì €ì¥
                save_chat_history_db([system_message], session_id=new_sid)
                
                return new_sid, f"ìƒˆ ì„¸ì…˜ ìƒì„±: {new_sid}"
        
            def apply_session(chosen_sid):
                """
                Dropdownì—ì„œ ì„ íƒëœ ì„¸ì…˜ IDë¡œ, DBì—ì„œ historyë¥¼ ë¶ˆëŸ¬ì˜¤ê³ , session_id_stateë¥¼ ê°±ì‹ 
                """
                if not chosen_sid:
                    return [], None, "ì„¸ì…˜ IDë¥¼ ì„ íƒí•˜ì„¸ìš”."
                loaded_history = load_chat_from_db(chosen_sid)
                logger.info(f"ë¶ˆëŸ¬ì˜¨ íˆìŠ¤í† ë¦¬: {loaded_history}")  # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
                # history_stateì— ë°˜ì˜í•˜ê³ , session_id_stateë„ ì—…ë°ì´íŠ¸
                return loaded_history, chosen_sid, f"ì„¸ì…˜ {chosen_sid}ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            def delete_session(chosen_sid, current_sid):
                """
                ì„ íƒëœ ì„¸ì…˜ì„ DBì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤.
                í˜„ì¬ í™œì„± ì„¸ì…˜ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
                """
                if not chosen_sid:
                    return "âŒ ì‚­ì œí•  ì„¸ì…˜ì„ ì„ íƒí•˜ì„¸ìš”.", False, gr.update()
                
                if chosen_sid == current_sid:
                    return "âŒ í˜„ì¬ í™œì„± ì„¸ì…˜ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", False, gr.update()
                
                try:
                    with sqlite3.connect("chat_history.db") as conn:
                        cursor = conn.cursor()
                        cursor.execute("SELECT COUNT(*) FROM chat_history WHERE session_id = ?", (chosen_sid,))
                        count = cursor.fetchone()[0]
                        
                        if count == 0:
                            logger.warning(f"ì„¸ì…˜ '{chosen_sid}'ì´(ê°€) DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                            return f"âŒ ì„¸ì…˜ '{chosen_sid}'ì´(ê°€) DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", False, gr.update(visible=False)
                        
                        cursor.execute("DELETE FROM chat_history WHERE session_id = ?", (chosen_sid,))
                        conn.commit()
                        
                    logger.info(f"ì„¸ì…˜ ì‚­ì œ ì™„ë£Œ: {chosen_sid}")
                    return f"âœ… ì„¸ì…˜ '{chosen_sid}'ì´(ê°€) ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", False, gr.update(visible=False)
                    
                except sqlite3.OperationalError as oe:
                    logger.critical(f"DB ìš´ì˜ ì˜¤ë¥˜: {oe}")
                    return f"âŒ DB ìš´ì˜ ì˜¤ë¥˜ ë°œìƒ: {oe}", False, gr.update(visible=False)
                except Exception as e:
                    logger.error(f"ì„¸ì…˜ ì‚­ì œ ì˜¤ë¥˜: {e}", exc_info=True)
                    return f"âŒ ì„¸ì…˜ ì‚­ì œ ì‹¤íŒ¨: {e}", False, gr.update(visible=False)
    
            
            def initiate_delete():
                return gr.update(visible=True), gr.update(visible=True)
            
            def confirm_delete(chosen_sid, current_sid, confirm):
                if not confirm:
                    return "âŒ ì‚­ì œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.", False, gr.update(visible=False)
                return delete_session(chosen_sid, current_sid)
        
            # ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            refresh_sessions_btn.click(
                fn=refresh_sessions,
                inputs=[],
                outputs=[existing_sessions_dropdown, session_manage_info]
            )
            
            def on_new_session_created(sid, info):
                """ìƒˆ ì„¸ì…˜ ìƒì„± ì‹œ ì´ˆê¸° íˆìŠ¤í† ë¦¬ ìƒì„±"""
                history = [{"role": "system", "content": DEFAULT_SYSTEM_MESSAGE}]
                return history, filter_messages_for_chatbot(history)
    
            # ê¸°ì¡´ì˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ìˆ˜ì •
            create_new_session_btn.click(
                fn=create_new_session,
                inputs=[],
                outputs=[session_id, session_manage_info]
            ).then(
                fn=on_new_session_created,
                inputs=[session_id, session_manage_info],
                outputs=[history, chatbot]
            )
    
            def on_session_applied(loaded_history, sid, info):
                """ì„¸ì…˜ ì ìš© ì‹œ ì±„íŒ… í‘œì‹œ ì—…ë°ì´íŠ¸"""
                return loaded_history, filter_messages_for_chatbot(loaded_history), info
    
            apply_session_btn.click(
                fn=apply_session,
                inputs=[existing_sessions_dropdown],
                outputs=[history, session_id, session_manage_info]
            ).then(
                fn=lambda h, s, i: (h, filter_messages_for_chatbot(h), i),
                inputs=[history, session_id, session_manage_info],
                outputs=[history, chatbot, session_manage_info]
            )
            
            delete_session_btn.click(
                fn=initiate_delete,
                inputs=[],
                outputs=[confirm_delete_checkbox, confirm_delete_btn]
            )
            
            # ì‚­ì œ í™•ì¸ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤ì œ ì‚­ì œ ìˆ˜í–‰
            confirm_delete_btn.click(
                fn=confirm_delete,
                inputs=[existing_sessions_dropdown, session_id, confirm_delete_checkbox],
                outputs=[session_manage_info, confirm_delete_checkbox, confirm_delete_btn]
            ).then(
                fn=refresh_sessions,  # ì„¸ì…˜ ì‚­ì œ í›„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
                inputs=[],
                outputs=[existing_sessions_dropdown, session_manage_info]
            )
    
    # ì¥ì¹˜ ì„¤ì • ì„¹ì…˜ ìœ ì§€
    with gr.Tab("ì¥ì¹˜ ì„¤ì •"):
        device_dropdown = gr.Dropdown(
            label="ì‚¬ìš©í•  ì¥ì¹˜ ì„ íƒ",
            choices=["Auto (Recommended)", "CPU", "GPU"],
            value="Auto (Recommended)",
            info="ìë™ ì„¤ì •ì„ ì‚¬ìš©í•˜ë©´ ì‹œìŠ¤í…œì— ë”°ë¼ ìµœì ì˜ ì¥ì¹˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."
        )
        device_info = gr.Textbox(
            label="ì¥ì¹˜ ì •ë³´",
            value=f"í˜„ì¬ ê¸°ë³¸ ì¥ì¹˜: {default_device.upper()}",
            interactive=False
        )
        def set_device(selection):
            """
            Sets the device based on user selection.
            - Auto: Automatically detect the best device.
            - CPU: Force CPU usage.
            - GPU: Detect and use CUDA or MPS based on available hardware.
            """
            if selection == "Auto (Recommended)":
                device = get_default_device()
            elif selection == "CPU":
                device = "cpu"
            elif selection == "GPU":
                if torch.cuda.is_available():
                    device = "cuda"
                elif platform.system() == "Darwin" and torch.backends.mps.is_available():
                    device = "mps"
                else:
                    return gr.update(value="âŒ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜ë©ë‹ˆë‹¤."), "cpu"
            else:
                device = "cpu"
            
            device_info_message = f"ì„ íƒëœ ì¥ì¹˜: {device.upper()}"
            logger.info(device_info_message)
            return gr.update(value=device_info_message), device
        
        device_dropdown.change(
            fn=set_device,
            inputs=[device_dropdown],
            outputs=[device_info, selected_device_state],
            queue=False
        )

demo.launch(debug=True, inbrowser=True, server_port=7861, width=500)